"""
ä½ç½®: test/test_expert_fno_diff_sorp.py
åŠŸèƒ½: æµ‹è¯• 1D Diff-Sorp çš„ FNO ä¸“å®¶æ¨¡å‹ (ä¿®å¤ cuFFT é”™è¯¯ä¸å†…å­˜è¿ç»­æ€§é—®é¢˜)
"""
import os
import sys
import torch
import h5py
import numpy as np
import matplotlib.pyplot as plt

# ================= é…ç½®åŒºåŸŸ =================
CONFIG = {
    "model_path": "../ExpertModels/ExpertModels_official/1D_diff-sorp_NA__FNO.pt",
    "data_path": "../data/1D_diff-sorp_NA_NA.h5",
    "output_dir": "OUTPUT/diff_sorp_fno_test",
    
    "modes": 16,
    "width": 64,
    "initial_step": 10,
    "num_channels": 1,
    
    "target_resolution": 64,  
    "seed": 0,
    
    # ğŸ”´ ä¿®æ”¹è¿™é‡Œï¼šå¼ºåˆ¶ä½¿ç”¨ cpuï¼Œç»•è¿‡ CUDA FFT é”™è¯¯
    "device": "cpu" 
    # "device": "cuda" if torch.cuda.is_available() else "cpu"
}

sys.path.append("..") 
try:
    from pdebench.models.fno.fno import FNO1d
except ImportError:
    sys.exit("âŒ é”™è¯¯: æ— æ³•å¯¼å…¥ pdebenchã€‚")

os.makedirs(CONFIG["output_dir"], exist_ok=True)

# ================= æ™ºèƒ½æ•°æ®åŠ è½½ =================
def load_diff_sorp_data(filename, seed_idx, target_resolution=None):
    print(f">>> Loading data from {filename} ...")
    if not os.path.exists(filename):
        raise FileNotFoundError(f"{filename} ä¸å­˜åœ¨")

    with h5py.File(filename, "r") as f:
        seed_str = str(seed_idx).zfill(4)
        if seed_str not in f: 
            seed_str = list(f.keys())[0]
            print(f"âš ï¸ Seed {seed_idx} not found, using {seed_str} instead.")
            
        group = f[seed_str]
        t = np.array(group["grid"]["t"], dtype=np.float32)
        x = np.array(group["grid"]["x"], dtype=np.float32)
        u_data = np.array(group["data"], dtype=np.float32) 
        
        # --- 1. ç»´åº¦ä¿®æ­£ ---
        if u_data.ndim == 3:
            u_data = u_data.squeeze(-1)
            
        nx = len(x)
        nt = len(t)
        
        print(f"   Raw Data Shape: {u_data.shape}, Grid x: {nx}, Grid t: {nt}")
        
        if u_data.shape[0] == nt and u_data.shape[1] == nx:
            print("   -> Detected (Time, Spatial), Transposing to (Spatial, Time)...")
            u_data = u_data.T
        elif u_data.shape[0] == nx and u_data.shape[1] == nt:
            print("   -> Detected (Spatial, Time), No transpose needed.")
        else:
            raise ValueError(f"âŒ æ•°æ®ç»´åº¦ {u_data.shape} ä¸ x({nx}), t({nt}) ä¸åŒ¹é…!")

    # --- 2. ç©ºé—´é™é‡‡æ · ---
    current_res = u_data.shape[0] # Spatial
    if target_resolution and current_res != target_resolution:
        print(f"âš ï¸ Resolution Mismatch: Spatial({current_res}) vs Model({target_resolution})")
        
        step = current_res // target_resolution
        print(f"   -> Performing Spatial Downsampling (step={step})...")
        
        # ä½¿ç”¨ np.copy ç¡®ä¿é™é‡‡æ ·åçš„æ•°ç»„åœ¨å†…å­˜ä¸­æ˜¯è¿ç»­çš„
        u_data = np.ascontiguousarray(u_data[::step, :])
        x = x[::step]
        
        print(f"   -> New Data Shape: {u_data.shape}")

    return u_data, x, t

# ================= ä¸»æµç¨‹ =================
def main():
    device = torch.device(CONFIG["device"])
    print(f"ğŸš€ Running on device: {device}")

    # 1. åŠ è½½æ•°æ®
    try:
        u_data, x_grid, t_grid = load_diff_sorp_data(CONFIG["data_path"], CONFIG["seed"], CONFIG["target_resolution"])
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½é”™è¯¯: {e}")
        return
        
    # [å…³é”®] æ£€æŸ¥ NaNs
    if np.isnan(u_data).any():
        print("âŒ é”™è¯¯: è¾“å…¥æ•°æ®åŒ…å« NaNï¼Œè¿™ä¼šå¯¼è‡´ cuFFT å´©æºƒã€‚")
        return

    # 2. åˆå§‹åŒ–æ¨¡å‹
    model = FNO1d(
        num_channels=CONFIG["num_channels"],
        modes=CONFIG["modes"],
        width=CONFIG["width"],
        initial_step=CONFIG["initial_step"]
    ).to(device)

    # 3. åŠ è½½æƒé‡
    model_path = CONFIG["model_path"]
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return

    try:
        checkpoint = torch.load(model_path, map_location=device)
        state_dict = checkpoint["model_state_dict"] if "model_state_dict" in checkpoint else checkpoint
        model.load_state_dict(state_dict)
        print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ!")
    except Exception as e:
        print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
        return

    model.eval()

    # 4. å‡†å¤‡æ¨ç†
    initial_step = CONFIG["initial_step"]
    time_dim = u_data.shape[1]
    
    # æ„é€  Grid: [1, S, 1]
    # ä½¿ç”¨ .contiguous() ç¡®ä¿å†…å­˜è¿ç»­
    grid_tensor = torch.tensor(x_grid, dtype=torch.float32).unsqueeze(0).unsqueeze(-1).to(device).contiguous()
    
    # æ„é€  Input: [1, S, T]
    input_full = torch.tensor(u_data, dtype=torch.float32).unsqueeze(0).to(device).contiguous()
    
    # å–å‰ initial_step æ­¥ä½œä¸ºåˆå§‹å†å²
    current_input = input_full[:, :, :initial_step].contiguous()

    preds = []
    # å¡«å…¥å†å²
    for i in range(initial_step):
        preds.append(u_data[:, i])

    print(f">>> Starting Autoregressive Inference (Steps: {initial_step} -> {time_dim})...")
    
    # æ¸…ç©ºç¼“å­˜ï¼Œç»™ FFT è…¾å‡ºå¹²å‡€çš„ç¯å¢ƒ
    if device.type == 'cuda':
        torch.cuda.empty_cache()

    try:
        with torch.no_grad():
            for t in range(initial_step, time_dim):
                # å†æ¬¡å¼ºåˆ¶ contiguousï¼Œé˜²æ­¢ cat/slice äº§ç”Ÿç¢ç‰‡
                curr_in_contig = current_input.contiguous()
                
                # FNO Forward
                # è¾“å‡º: [1, S, 1, 1] -> squeeze -> [1, S, 1]
                prediction = model(curr_in_contig, grid_tensor).squeeze(-2) 
                
                # å­˜ç»“æœ
                pred_val = prediction[0, :, 0].cpu().numpy()
                preds.append(pred_val)
                
                # æ›´æ–°å†å²: ä¸¢å¼ƒæœ€æ—©çš„ä¸€å¸§ï¼ŒåŠ å…¥é¢„æµ‹çš„ä¸€å¸§
                # [1, S, 10] -> [1, S, 9] + [1, S, 1]
                current_input = torch.cat([current_input[:, :, 1:], prediction], dim=-1)

                if t % 20 == 0:
                    print(f"   Step {t}/{time_dim}", end="\r")

    except RuntimeError as e:
        print(f"\nâŒ æ¨ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        if "CUFFT" in str(e):
            print("ğŸ’¡ æç¤º: CUFFT é”™è¯¯é€šå¸¸ä¸å†…å­˜å¸ƒå±€æœ‰å…³ã€‚å¦‚æœé—®é¢˜æŒç»­ï¼Œå°è¯•åœ¨ CPU ä¸Šè¿è¡Œ (CONFIG['device']='cpu') ä»¥æ’é™¤ GPU é©±åŠ¨é—®é¢˜ã€‚")
        return

    print(f"\nâœ… Inference Done. Total frames: {len(preds)}")
    
    # 5. åå¤„ç†ä¸è¯„ä¼°
    preds = np.array(preds).T 
    
    # å¯¹é½é•¿åº¦
    min_len = min(preds.shape[1], u_data.shape[1])
    preds = preds[:, :min_len]
    u_data_trunc = u_data[:, :min_len]

    # è®¡ç®— MSE
    mse = np.mean((preds[:, initial_step:] - u_data_trunc[:, initial_step:]) ** 2)
    print(f"ğŸ“Š MSE: {mse:.4e}")

    # 6. ç»˜å›¾
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 3, 1)
    plot_indices = [int(min_len*0.2), int(min_len*0.5), int(min_len*0.8)]
    for idx in plot_indices:
        if idx < min_len:
            plt.plot(x_grid, u_data_trunc[:, idx], 'k--', alpha=0.5, label='GT' if idx==plot_indices[0] else None)
            plt.plot(x_grid, preds[:, idx], '-', label=f't={t_grid[idx]:.1f}')
    plt.title(f"Snapshots (MSE={mse:.2e})")
    plt.legend()
    
    plt.subplot(1, 3, 2)
    plt.imshow(u_data_trunc, aspect='auto', cmap='jet', origin='lower')
    plt.title("Ground Truth")
    plt.xlabel("t")
    plt.ylabel("x")
    plt.colorbar()
    
    plt.subplot(1, 3, 3)
    plt.imshow(preds, aspect='auto', cmap='jet', origin='lower')
    plt.title("FNO Prediction")
    plt.xlabel("t")
    plt.colorbar()
    
    save_path = os.path.join(CONFIG["output_dir"], "diff_sorp_fno_result.png")
    plt.tight_layout()
    plt.savefig(save_path)
    print(f"ğŸ–¼ï¸ Saved plot to {save_path}")

if __name__ == "__main__":
    main()