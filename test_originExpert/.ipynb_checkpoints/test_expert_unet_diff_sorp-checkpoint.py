"""
ä½ç½®: test_codes/test_expert_unet_diff_sorp.py
åŠŸèƒ½: æµ‹è¯• Diff-Sorp U-Net (æ”¯æŒæŸåæ£€æµ‹ + è‡ªåŠ¨é™é‡‡æ ·é€‚é… 64åˆ†è¾¨çŽ‡æ¨¡åž‹)
"""
import os
import sys
import torch
import h5py
import numpy as np
import matplotlib.pyplot as plt

# ================= é…ç½® =================
CONFIG = {
    # åœ¨è¿™é‡Œåˆ‡æ¢ä½ æƒ³æµ‹è¯•çš„æ¨¡åž‹
    "model_path": "../ExpertModels/1D_diff-sorp_NA__Unet-PF-20.pt", 
    # "model_path": "../ExpertModels/1D_diff-sorp_NA__Unet-PF-20.pt", 
    
    "data_path": "../data/1D_diff-sorp_NA_NA.h5",
    "output_dir": "../OUTPUT/diff_sorp_unet_test",
    "in_channels": 10,
    "out_channels": 1,
    "init_features": 32,
    "seed": 0,
    "device": "cuda" if torch.cuda.is_available() else "cpu"
}

sys.path.append("..") 
try:
    from pdebench.models.unet.unet import UNet1d
except ImportError:
    sys.exit("âŒ é”™è¯¯: æ— æ³•å¯¼å…¥ pdebenchã€‚")

os.makedirs(CONFIG["output_dir"], exist_ok=True)

# ================= æ•°æ®åŠ è½½ (å«è‡ªåŠ¨é™é‡‡æ ·) =================
def load_diff_sorp_data(filename, seed_idx, target_resolution=None):
    print(f">>> Loading data from {filename} ...")
    with h5py.File(filename, "r") as f:
        seed_str = str(seed_idx).zfill(4)
        if seed_str not in f: seed_str = list(f.keys())[0]
        group = f[seed_str]
        t = np.array(group["grid"]["t"], dtype=np.float32)
        x = np.array(group["grid"]["x"], dtype=np.float32)
        u_data = np.array(group["data"], dtype=np.float32) 
        
        if u_data.shape[0] == len(x) and u_data.shape[1] == len(t):
            u_data = np.transpose(u_data, (1, 0, 2))
            
    # --- è‡ªåŠ¨é™é‡‡æ ·é€»è¾‘ ---
    current_res = u_data.shape[1]
    if target_resolution and current_res != target_resolution:
        print(f"âš ï¸ Resolution Mismatch: Data({current_res}) vs Model({target_resolution})")
        print(f"   -> Performing Downsampling...")
        
        # è®¡ç®—æ­¥é•¿ (ä¾‹å¦‚ 1024 -> 64, step=16)
        step = current_res // target_resolution
        if current_res % target_resolution != 0:
            print("   âš ï¸ Warning: ä¸èƒ½æ•´é™¤ï¼Œå¯èƒ½ä¼šæœ‰æˆªæ–­åå·®")
            
        # æ‰§è¡Œåˆ‡ç‰‡é™é‡‡æ ·
        u_data = u_data[:, ::step, :]
        x = x[::step]
        print(f"   -> New Data Shape: {u_data.shape}")

    return u_data, x, t

# ================= ä¸»æµç¨‹ =================
def main():
    device = torch.device(CONFIG["device"])
    
    # 1. æ™ºèƒ½åˆ¤æ–­æ¨¡åž‹åˆ†è¾¨çŽ‡
    target_res = None
    if "64_resolution" in CONFIG["model_path"]:
        target_res = 64
        print("ðŸ’¡ Detected '64_resolution' model, setting target resolution to 64.")
    
    # 2. åŠ è½½æ•°æ®
    try:
        u_data, x_grid, t_grid = load_diff_sorp_data(CONFIG["data_path"], CONFIG["seed"], target_res)
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return

    # 3. åŠ è½½æ¨¡åž‹
    print(f">>> Loading U-Net Model: {CONFIG['model_path']}")
    model = UNet1d(CONFIG["in_channels"], CONFIG["out_channels"], CONFIG["init_features"]).to(device)
    
    if not os.path.exists(CONFIG["model_path"]):
        print(f"âŒ æ¨¡åž‹æ–‡ä»¶ä¸å­˜åœ¨: {CONFIG['model_path']}")
        return

    try:
        checkpoint = torch.load(CONFIG["model_path"], map_location=device)
        state_dict = checkpoint["model_state_dict"] if "model_state_dict" in checkpoint else checkpoint
        model.load_state_dict(state_dict)
        print("âœ… æ¨¡åž‹æƒé‡åŠ è½½æˆåŠŸ!")
    except RuntimeError as e:
        print(f"âŒ [ä¸¥é‡é”™è¯¯] æƒé‡åŠ è½½å¤±è´¥: {e}")
        print("ðŸ’¡ åŽŸå› å¯èƒ½æ˜¯æ–‡ä»¶æŸåï¼Œæˆ–è€…ä½ çš„ Git LFS ä¸‹è½½ä¸å®Œæ•´ã€‚")
        return
    except Exception as e:
        print(f"âŒ æ–‡ä»¶è¯»å–é”™è¯¯: {e}")
        return

    model.eval()

    # 4. æŽ¨ç† (æ»‘åŠ¨çª—å£)
    window_size = CONFIG["in_channels"]
    total_steps = len(t_grid)
    preds = []
    
    # å¡«å…¥åŽ†å²
    history_buffer = u_data[:window_size, :, 0]
    for i in range(window_size): preds.append(history_buffer[i])
    current_input = torch.tensor(history_buffer).unsqueeze(0).float().to(device) # [1, 10, 64]

    print(f">>> Predicting...")
    with torch.no_grad():
        for t in range(window_size, total_steps):
            prediction = model(current_input) # [1, 1, 64]
            pred_frame = prediction.cpu().numpy()[0, 0]
            preds.append(pred_frame)
            current_input = torch.cat([current_input[:, 1:, :], prediction], dim=1)

    preds = np.array(preds)
    truths = u_data[:, :, 0]
    mse = np.mean((preds[window_size:] - truths[window_size:]) ** 2)
    print(f"âœ… MSE: {mse:.4e}")

    # 5. ç»˜å›¾
    plt.figure(figsize=(15, 5))
    snap_indices = [15, 50, 90]
    for i, idx in enumerate(snap_indices):
        if idx >= total_steps: break
        plt.subplot(1, 3, i+1)
        plt.plot(x_grid, truths[idx], 'k--', label='GT')
        plt.plot(x_grid, preds[idx], 'r-', label='Pred')
        plt.title(f"t={t_grid[idx]:.1f}")
        if i==0: plt.legend()
    
    save_path = os.path.join(CONFIG["output_dir"], "unet_64_result.png")
    plt.savefig(save_path)
    print(f"Saved: {save_path}")

if __name__ == "__main__":
    main()